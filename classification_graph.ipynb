{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.4"},"colab":{"name":"classification_graph.ipynb","provenance":[]}},"cells":[{"cell_type":"code","metadata":{"id":"PZ6No36yTkPs","colab_type":"code","outputId":"0a7d6f9b-109c-4582-9a2b-c72f64a16538","executionInfo":{"status":"ok","timestamp":1582498870513,"user_tz":-60,"elapsed":30346,"user":{"displayName":"Ramzi Charradi","photoUrl":"","userId":"07339686973202329929"}},"colab":{"base_uri":"https://localhost:8080/","height":122}},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"X5zAL4ufTmJP","colab_type":"code","outputId":"007d702a-caea-4ca2-a64d-ea8761bfbd22","executionInfo":{"status":"ok","timestamp":1582498874451,"user_tz":-60,"elapsed":1012,"user":{"displayName":"Ramzi Charradi","photoUrl":"","userId":"07339686973202329929"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["cd /content/drive/My Drive/altegrad"],"execution_count":2,"outputs":[{"output_type":"stream","text":["/content/drive/My Drive/altegrad\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"BrMl_GMmTwNQ","colab_type":"code","outputId":"de021b5e-2329-4d47-e44a-356f8adfe9f1","executionInfo":{"status":"ok","timestamp":1582498881964,"user_tz":-60,"elapsed":6927,"user":{"displayName":"Ramzi Charradi","photoUrl":"","userId":"07339686973202329929"}},"colab":{"base_uri":"https://localhost:8080/","height":156}},"source":["!pip install python-igraph"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Collecting python-igraph\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f3/23/2959ac50ac7a3d8c28602a752075abd21025767fc32d4587fb35ae273d22/python_igraph-0.8.0-cp36-cp36m-manylinux2010_x86_64.whl (3.2MB)\n","\u001b[K     |████████████████████████████████| 3.2MB 2.8MB/s \n","\u001b[?25hCollecting texttable>=1.6.2\n","  Downloading https://files.pythonhosted.org/packages/ec/b1/8a1c659ce288bf771d5b1c7cae318ada466f73bd0e16df8d86f27a2a3ee7/texttable-1.6.2-py2.py3-none-any.whl\n","Installing collected packages: texttable, python-igraph\n","Successfully installed python-igraph-0.8.0 texttable-1.6.2\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"rSh6TACXTihP","colab_type":"code","outputId":"d32a3e54-08c4-4ed0-c081-5bcf504a8ac9","executionInfo":{"status":"error","timestamp":1582498887539,"user_tz":-60,"elapsed":863,"user":{"displayName":"Ramzi Charradi","photoUrl":"","userId":"07339686973202329929"}},"colab":{"base_uri":"https://localhost:8080/","height":367}},"source":["import pandas as pd\n","import numpy as np\n","from tqdm import tqdm\n","from pathlib import Path\n","import matplotlib.pyplot as plt\n","plt.style.use('ggplot')\n","from warnings import simplefilter\n","# ignore all future warnings\n","simplefilter(action='ignore', category=FutureWarning)\n","simplefilter(action='ignore', category=DeprecationWarning)\n","import csv\n","import networkx as nx\n","import os\n","\n","from src.preprocess import read_data, pre_process_text, filter_text\n","from src.k_core import get_k_core\n","from src.word2vec import Word2Vec, BagOfWords"],"execution_count":4,"outputs":[{"output_type":"error","ename":"ModuleNotFoundError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","\u001b[0;32m<ipython-input-4-5258645a2560>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocess\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mread_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpre_process_text\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilter_text\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mk_core\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mget_k_core\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword2vec\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mWord2Vec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBagOfWords\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'src'","","\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"]}]},{"cell_type":"code","metadata":{"id":"mSmmBx-LTihU","colab_type":"code","colab":{}},"source":["# path of files to read :\n","train_data = \"data/train_noduplicates.csv\"\n","test_data  = \"data/test.csv\"\n","texts_path = \"data/text/text\"\n","\n","# preprocessing :\n","num_words = 2000\n","do_stem = False\n","do_tokenize = False"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"7PA64MHwTihW","colab_type":"code","outputId":"11a20c65-ff21-487b-b344-906ab49e8b15","colab":{}},"source":["# read data\n","df, test_df = read_data(train_data, test_data, texts_path)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["reading training data ...\n","reading test data ...\n","reading text files ...\n","finished\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"ad21WnIXTiha","colab_type":"code","outputId":"e5c53b24-31b8-4813-9e65-cf8677f8f7ea","colab":{}},"source":["# preprocess data\n","tqdm.pandas()\n","print(\"Preprocessing training data...\")\n","df[\"text\"] = df[\"text\"].progress_apply( lambda x : pre_process_text(x, num_words, do_stem, do_tokenize))\n","print(\"Preprocessing test data...\")\n","test_df[\"text\"] = test_df[\"text\"].progress_apply( lambda x : pre_process_text(x, num_words, do_stem, do_tokenize))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Preprocessing training data...\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████████████████████████████████████████████████████████████████████████| 1994/1994 [02:56<00:00, 11.32it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["Preprocessing test data...\n"],"name":"stdout"},{"output_type":"stream","text":["100%|████████████████████████████████████████████████████████████████████████████████| 560/560 [00:49<00:00, 11.42it/s]\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"BnK4YYGLTihd","colab_type":"code","outputId":"c9458886-dc04-44a1-e12c-e87f9f567adb","colab":{}},"source":["# Read training data\n","print(\"reading training data ...\")\n","with open(train_data, 'r') as f:\n","    train_data = f.read().splitlines()\n","    train_hosts = list()\n","    y_train = list()\n","    for row in train_data:\n","        host, label = row.split(\",\")\n","        train_hosts.append(host)\n","        y_train.append(label.lower())\n","            \n","# Read test data\n","print(\"reading test data ...\")\n","with open(test_data, 'r') as f:\n","    test_hosts = f.read().splitlines()"],"execution_count":0,"outputs":[{"output_type":"stream","text":["reading training data ...\n","reading test data ...\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"QrAsYFeOTihh","colab_type":"code","colab":{}},"source":["df[\"node\"] = train_hosts\n","test_df[\"node\"] = test_hosts"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"jGKZpOIYTihk","colab_type":"code","colab":{}},"source":["# convert labels\n","classes = {\"business/finance\":0,\"education/research\":1,\"entertainment\":2,\"health/medical\":3,\"news/press\":4, \\\n","           \"politics/government/law\":5, \"sports\":6, \"tech/science\":7}\n","for i in range(len(df)):\n","    df.label[i] = classes[df.label[i]]"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"RVAEO-eVTihn","colab_type":"code","outputId":"8601e789-9eb6-40f1-f850-af1e4724deef","colab":{}},"source":["df.head(2)"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>text</th>\n","      <th>label</th>\n","      <th>node</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>0</td>\n","      <td>de polepharma d r les la inscription du agglo ...</td>\n","      <td>3</td>\n","      <td>9032</td>\n","    </tr>\n","    <tr>\n","      <td>1</td>\n","      <td>moved permanently nginx</td>\n","      <td>2</td>\n","      <td>5346</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                                text label  node\n","0  de polepharma d r les la inscription du agglo ...     3  9032\n","1                            moved permanently nginx     2  5346"]},"metadata":{"tags":[]},"execution_count":13}]},{"cell_type":"code","metadata":{"id":"zI3IDZa1Tihp","colab_type":"code","outputId":"43a7382a-9cfe-4f0d-af7d-71ea7b9f43af","colab":{}},"source":["# Create a directed, weighted graph\n","graph = nx.read_weighted_edgelist('./data/edgelist.txt', create_using=nx.DiGraph())\n","graph.remove_edges_from(nx.selfloop_edges(graph))\n","print(graph.number_of_nodes())\n","print(graph.number_of_edges())"],"execution_count":0,"outputs":[{"output_type":"stream","text":["28002\n","319498\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"jMYavEttTihs","colab_type":"code","colab":{}},"source":["X_train = [str(df.text[i]) for i in range(len(df))]\n","X_sub = [str(df.text[i]) for i in range(len(df))]"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"SCDgwQjRTihv","colab_type":"code","colab":{}},"source":["from sklearn.feature_extraction.text import TfidfVectorizer\n","vec = TfidfVectorizer(decode_error='ignore', strip_accents='unicode', encoding='latin-1', min_df=10, max_df=1000)\n","X_train_tfidf = vec.fit_transform(X_train)\n","X_sub_tfidf = vec.transform(X_sub)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"su6JeOYmTihx","colab_type":"code","outputId":"21489bb3-cbc0-4d67-b985-77e96b2070d6","colab":{}},"source":["X_train_tfidf.shape"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(1994, 16710)"]},"metadata":{"tags":[]},"execution_count":27}]},{"cell_type":"markdown","metadata":{"id":"KoC3t1l4MUpZ","colab_type":"text"},"source":["# start"]},{"cell_type":"code","metadata":{"id":"Xsdr3Y5jMZEa","colab_type":"code","colab":{}},"source":["X_nodes = np.load('./saved_files/X_nodes.npy')\n","sub_nodes = np.load('./saved_files/sub_nodes.npy')\n","features_train = np.load('./saved_files/features_train.npy')\n","features_subm = np.load('./saved_files/features_subm.npy')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"QwHt9VEqM86d","colab_type":"code","outputId":"774ee123-ce92-4090-fc67-6893c7c9e8e1","executionInfo":{"status":"ok","timestamp":1582301525971,"user_tz":-60,"elapsed":13,"user":{"displayName":"Ramzi Charradi","photoUrl":"","userId":"07339686973202329929"}},"colab":{"base_uri":"https://localhost:8080/"}},"source":["!pip install torch_sparse"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Collecting torch_sparse\n","  Downloading https://files.pythonhosted.org/packages/92/80/7137d14dac46d515373d8b3eb47e2565ecfd646ba8658a6a6a1c24e49a2c/torch_sparse-0.5.1.tar.gz\n","Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from torch_sparse) (1.4.1)\n","Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.6/dist-packages (from scipy->torch_sparse) (1.17.5)\n","Building wheels for collected packages: torch-sparse\n","  Building wheel for torch-sparse (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for torch-sparse: filename=torch_sparse-0.5.1-cp36-cp36m-linux_x86_64.whl size=9762135 sha256=4535d16d9e93153422119430e00003dfd49d4182fbce25e57597d530e5012598\n","  Stored in directory: /root/.cache/pip/wheels/3a/53/0f/9607e81ab5da3964d74aa01e948fb4234136ae5ea6e28ba1ae\n","Successfully built torch-sparse\n","Installing collected packages: torch-sparse\n","Successfully installed torch-sparse-0.5.1\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"TDBrmmCmTihz","colab_type":"code","colab":{}},"source":["# parameters\n","model = \"exact\"\n","epochs =2000\n","seed = 42\n","iterations = 10\n","early_stopping_rounds = 500,\n","train_size = 1500\n","test_size = 494\n","dropout = 0.5\n","alpha  =0.1\n","learning_rate =0.01\n","lambd = 0.005\n","layers = [64, 64]"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"8ym--GfKTih1","colab_type":"code","outputId":"d64c0d96-561a-48e5-85f4-19ed75d46499","executionInfo":{"status":"error","timestamp":1582296219251,"user_tz":-60,"elapsed":3330,"user":{"displayName":"Ramzi Charradi","photoUrl":"","userId":"07339686973202329929"}},"colab":{"base_uri":"https://localhost:8080/","height":363}},"source":["# layers of the model\n","import math\n","import torch\n","from torch_sparse import spmm\n","\n","\n","def create_propagator_matrix(graph, alpha, model):\n","    \"\"\"\n","    Creating  apropagation matrix.\n","    :param graph: NetworkX graph.\n","    :param alpha: Teleport parameter.\n","    :param model: Type of model exact or approximate.\n","    :return propagator: Propagator matrix Dense torch matrix /\n","    dict with indices and values for sparse multiplication.\n","    \"\"\"\n","    A = create_adjacency_matrix(graph)\n","    I = sparse.eye(A.shape[0])\n","    A_tilde_hat = normalize_adjacency_matrix(A, I)\n","    if model == \"exact\":\n","        propagator = (I-(1-alpha)*A_tilde_hat).todense()\n","        propagator = alpha*torch.inverse(torch.FloatTensor(propagator))\n","    else:\n","        propagator = dict()\n","        A_tilde_hat = sparse.coo_matrix(A_tilde_hat)\n","        indices = np.concatenate([A_tilde_hat.row.reshape(-1, 1), A_tilde_hat.col.reshape(-1, 1)], axis=1).T\n","        propagator[\"indices\"] = torch.LongTensor(indices)\n","        propagator[\"values\"] = torch.FloatTensor(A_tilde_hat.data)\n","    return propagator\n","\n","\n","def uniform(size, tensor):\n","    \"\"\"\n","    Uniform weight initialization.\n","    :param size: Size of the tensor.\n","    :param tensor: Tensor initialized.\n","    \"\"\"\n","    stdv = 1.0 / math.sqrt(size)\n","    if tensor is not None:\n","        tensor.data.uniform_(-stdv, stdv)\n","\n","class DenseFullyConnected(torch.nn.Module):\n","    \"\"\"\n","    Abstract class for PageRank and Approximate PageRank networks.\n","    :param in_channels: Number of input channels.\n","    :param out_channels: Number of output channels.\n","    :param density: Feature matrix structure.\n","    \"\"\"\n","    def __init__(self, in_channels, out_channels):\n","        super(DenseFullyConnected, self).__init__()\n","        self.in_channels = in_channels\n","        self.out_channels = out_channels\n","        self.define_parameters()\n","        self.init_parameters()\n","\n","    def define_parameters(self):\n","        \"\"\"\n","        Defining the weight matrices.\n","        \"\"\"\n","        self.weight_matrix = torch.nn.Parameter(torch.Tensor(self.in_channels, self.out_channels))\n","        self.bias = torch.nn.Parameter(torch.Tensor(self.out_channels))\n","\n","    def init_parameters(self):\n","        \"\"\"\n","        Initializing weights.\n","        \"\"\"\n","        torch.nn.init.xavier_uniform_(self.weight_matrix)\n","        uniform(self.out_channels, self.bias)\n","\n","    def forward(self, features):\n","        \"\"\"\n","        Doing a forward pass.\n","        :param features: Feature matrix.\n","        :return filtered_features: Convolved features.\n","        \"\"\"\n","        filtered_features = torch.mm(features, self.weight_matrix)\n","        filtered_features = filtered_features + self.bias\n","        return filtered_features\n","\n","class SparseFullyConnected(torch.nn.Module):\n","    \"\"\"\n","    Abstract class for PageRank and Approximate PageRank networks.\n","    :param in_channels: Number of input channels.\n","    :param out_channels: Number of output channels.\n","    :param density: Feature matrix structure.\n","    \"\"\"\n","    def __init__(self, in_channels, out_channels):\n","        super(SparseFullyConnected, self).__init__()\n","        self.in_channels = in_channels\n","        self.out_channels = out_channels\n","        self.define_parameters()\n","        self.init_parameters()\n","\n","    def define_parameters(self):\n","        \"\"\"\n","        Defining the weight matrices.\n","        \"\"\"\n","        self.weight_matrix = torch.nn.Parameter(torch.Tensor(self.in_channels, self.out_channels))\n","        self.bias = torch.nn.Parameter(torch.Tensor(self.out_channels))\n","\n","    def init_parameters(self):\n","        \"\"\"\n","        Initializing weights.\n","        \"\"\"\n","        torch.nn.init.xavier_uniform_(self.weight_matrix)\n","        uniform(self.out_channels, self.bias)\n","\n","    def forward(self, feature_indices, feature_values):\n","        \"\"\"\n","        Making a forward pass.\n","        :param feature_indices: Non zero value indices.\n","        :param feature_values: Matrix values.\n","        :return filtered_features: Output features.\n","        \"\"\"\n","        number_of_nodes = torch.max(feature_indices[0]).item()+1\n","        number_of_features = torch.max(feature_indices[1]).item()+1\n","        filtered_features = spmm(index = feature_indices,\n","                                 value = feature_values,\n","                                 m = number_of_nodes,\n","                                 n = number_of_features,\n","                                 matrix = self.weight_matrix)\n","        filtered_features = filtered_features + self.bias\n","        return filtered_features\n","\n","class APPNPModel(torch.nn.Module):\n","    \"\"\"\n","    APPNP Model Class.\n","    :param args: Arguments object.\n","    :param number_of_labels: Number of target labels.\n","    :param number_of_features: Number of input features.\n","    :param graph: NetworkX graph.\n","    :param device: CPU or GPU.\n","    \"\"\"\n","    def __init__(self, args, number_of_labels, number_of_features, graph, device):\n","        super(APPNPModel, self).__init__()\n","        self.args = args\n","        self.number_of_labels = number_of_labels\n","        self.number_of_features = number_of_features\n","        self.graph = graph\n","        self.device = device\n","        self.setup_layers()\n","        self.setup_propagator()\n","\n","    def setup_layers(self):\n","        \"\"\"\n","        Creating layers.\n","        \"\"\"\n","        self.layer_1 = SparseFullyConnected(self.number_of_features, self.args.layers[0])\n","        self.layer_2 = DenseFullyConnected(self.args.layers[1], self.number_of_labels)\n","\n","    def setup_propagator(self):\n","        \"\"\"\n","        Defining propagation matrix (Personalized Pagrerank or adjacency).\n","        \"\"\"\n","        self.propagator = create_propagator_matrix(self.graph, self.args.alpha, self.args.model)\n","        if self.args.model == \"exact\":\n","            self.propagator = self.propagator.to(self.device)\n","        else:\n","            self.edge_indices = self.propagator[\"indices\"].to(self.device)\n","            self.edge_weights = self.propagator[\"values\"].to(self.device)\n","\n","    def forward(self, feature_indices, feature_values):\n","        \"\"\"\n","        Making a forward propagation pass.\n","        :param feature_indices: Feature indices for feature matrix.\n","        :param feature_values: Values in the feature matrix.\n","        :return self.predictions: Predicted class label log softmaxes.\n","        \"\"\"\n","        feature_values = torch.nn.functional.dropout(feature_values,\n","                                                     p=self.args.dropout,\n","                                                     training=self.training)\n","\n","        latent_features_1 = self.layer_1(feature_indices, feature_values)\n","\n","        latent_features_1 = torch.nn.functional.relu(latent_features_1)\n","\n","        latent_features_1 = torch.nn.functional.dropout(latent_features_1,\n","                                                        p=self.args.dropout,\n","                                                        training=self.training)\n","\n","        latent_features_2 = self.layer_2(latent_features_1)\n","        if self.args.model == \"exact\":\n","            self.predictions = torch.nn.functional.dropout(self.propagator,\n","                                                           p=self.args.dropout,\n","                                                           training=self.training)\n","\n","            self.predictions = torch.mm(self.predictions, latent_features_2)\n","        else:\n","            localized_predictions = latent_features_2\n","            edge_weights = torch.nn.functional.dropout(self.edge_weights,\n","                                                       p=self.args.dropout,\n","                                                       training=self.training)\n","\n","            for iteration in range(self.args.iterations):\n","\n","                new_features = spmm(index=self.edge_indices,\n","                                    value=edge_weights,\n","                                    n=localized_predictions.shape[0],\n","                                    m=localized_predictions.shape[0],\n","                                    matrix=localized_predictions)\n","\n","                localized_predictions = (1-self.args.alpha)*new_features\n","                localized_predictions = localized_predictions + self.args.alpha*latent_features_2\n","            self.predictions = localized_predictions\n","        self.predictions = torch.nn.functional.log_softmax(self.predictions, dim=1)\n","        return self.predictions"],"execution_count":0,"outputs":[{"output_type":"error","ename":"ModuleNotFoundError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","\u001b[0;32m<ipython-input-11-83a0109fe6d1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch_sparse\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mspmm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'torch_sparse'","","\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"]}]},{"cell_type":"code","metadata":{"id":"6xbmEVrBTih3","colab_type":"code","colab":{}},"source":["import random\n","import torch\n","import numpy as np\n","from tqdm import trange\n","\n","class APPNPTrainer(object):\n","    \"\"\"\n","    Method to train PPNP/APPNP model.\n","    \"\"\"\n","    def __init__(self, args, graph, features, target):\n","        \"\"\"\n","        :param args: Arguments object.\n","        :param graph: Networkx graph.\n","        :param features: Feature matrix.\n","        :param target: Target vector with labels.\n","        \"\"\"\n","        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","        self.args = args\n","        self.graph = graph\n","        self.features = features\n","        self.target = target\n","        self.create_model()\n","        self.train_test_split()\n","        self.transfer_node_sets()\n","        self.process_features()\n","        self.transfer_features()\n","\n","    def create_model(self):\n","        \"\"\"\n","        Defining a model and transfering it to GPU/CPU.\n","        \"\"\"\n","        self.node_count = self.graph.number_of_nodes()\n","        self.number_of_labels = np.max(self.target)+1\n","        self.number_of_features = max([f for _, feats  in self.features.items() for f in feats])+1\n","\n","        self.model = APPNPModel(self.args,\n","                                self.number_of_labels,\n","                                self.number_of_features,\n","                                self.graph,\n","                                self.device)\n","\n","        self.model = self.model.to(self.device)\n","\n","    def train_test_split(self):\n","        \"\"\"\n","        Creating a train/test split.\n","        \"\"\"\n","        random.seed(self.args.seed)\n","        nodes = [node for node in range(self.node_count)]\n","        random.shuffle(nodes)\n","        self.train_nodes = nodes[0:self.args.train_size]\n","        self.test_nodes = nodes[self.args.train_size:self.args.train_size+self.args.test_size]\n","        self.validation_nodes = nodes[self.args.train_size+self.args.test_size:]\n","\n","    def transfer_node_sets(self):\n","        \"\"\"\n","        Transfering the node sets to the device.\n","        \"\"\"\n","        self.train_nodes = torch.LongTensor(self.train_nodes).to(self.device)\n","        self.test_nodes = torch.LongTensor(self.test_nodes).to(self.device)\n","        self.validation_nodes = torch.LongTensor(self.validation_nodes).to(self.device)\n","\n","    def process_features(self):\n","        \"\"\"\n","        Creating a sparse feature matrix and a vector for the target labels.\n","        \"\"\"\n","        index_1 = [node for node in self.graph.nodes() for fet in self.features[node]]\n","        index_2 = [fet for node in self.graph.nodes() for fet in self.features[node]]\n","        values = [1.0/len(self.features[node]) for node in self.graph.nodes() for fet in self.features[node]]\n","        self.feature_indices = torch.LongTensor([index_1, index_2])\n","        self.feature_values = torch.FloatTensor(values)\n","        self.target = torch.LongTensor(self.target)\n","\n","    def transfer_features(self):\n","        \"\"\"\n","        Transfering the features and the target matrix to the device.\n","        \"\"\"\n","        self.target = self.target.to(self.device)\n","        self.feature_indices = self.feature_indices.to(self.device)\n","        self.feature_values = self.feature_values.to(self.device)\n","\n","    def score(self, index_set):\n","        \"\"\"\n","        Calculating the accuracy for a given node set.\n","        :param index_set: Index of nodes to be included in calculation.\n","        :parm acc: Accuracy score.\n","        \"\"\"\n","        self.model.eval()\n","        _, pred = self.model(self.feature_indices, self.feature_values).max(dim=1)\n","        correct = pred[index_set].eq(self.target[index_set]).sum().item()\n","        acc = correct / index_set.size()[0]\n","        return acc\n","\n","    def do_a_step(self):\n","        \"\"\"\n","        Doing an optimization step.\n","        \"\"\"\n","        self.model.train()\n","        self.optimizer.zero_grad()\n","        prediction = self.model(self.feature_indices, self.feature_values)\n","        loss = torch.nn.functional.nll_loss(prediction[self.train_nodes],\n","                                            self.target[self.train_nodes])\n","        loss = loss+(self.args.lambd/2)*(torch.sum(self.model.layer_2.weight_matrix**2))\n","        loss.backward()\n","        self.optimizer.step()\n","\n","    def train_neural_network(self):\n","        \"\"\"\n","        Training a neural network.\n","        \"\"\"\n","        print(\"\\nTraining.\\n\")\n","        self.optimizer = torch.optim.Adam(self.model.parameters(), lr=self.args.learning_rate)\n","        self.best_accuracy = 0\n","        self.step_counter = 0\n","        iterator = trange(self.args.epochs, desc='Validation accuracy: ', leave=True)\n","        for _ in iterator:\n","            self.do_a_step()\n","            accuracy = self.score(self.validation_nodes)\n","            iterator.set_description(\"Validation accuracy: {:.4f}\".format(accuracy))\n","            if accuracy >= self.best_accuracy:\n","                self.best_accuracy = accuracy\n","                self.test_accuracy = self.score(self.test_nodes)\n","                self.step_counter = 0\n","            else:\n","                self.step_counter = self.step_counter + 1\n","                if self.step_counter > self.args.early_stopping_rounds:\n","                    iterator.close()\n","                    break\n","\n","    def fit(self):\n","        \"\"\"\n","        Fitting the network and calculating the test accuracy.\n","        \"\"\"\n","        self.train_neural_network()\n","        print(\"\\nBreaking from training process because of early stopping.\\n\")\n","        print(\"Test accuracy: {:.4f}\".format(self.test_accuracy))"],"execution_count":0,"outputs":[]}]}